{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport tweepy\nimport csv\nimport os\nimport pandas as pd\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport spacy\nfrom sklearn.model_selection import train_test_split\nimport nltk\nnltk.download('stopwords')\nnltk.download('wordnet')\nfrom nltk.tokenize import RegexpTokenizer, WhitespaceTokenizer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nimport string\nfrom string import punctuation\nimport collections\nfrom collections import Counter\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nimport en_core_web_sm\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# !pip3 install -U spacy\n# !python3 -m spacy download en_core_web_sm\n\nfrom sklearn.metrics import jaccard_score","execution_count":21,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport glob\nimport pandas as pd\nextension = 'csv'\ndataframes = []\nall_filenames = [i for i in glob.glob('*.{}'.format(extension))]\nfor f in all_filenames:\n    frame = pd.read_csv(f)\n    df = pd.DataFrame()\n    df['tweets'] = frame['text']\n    dataframes.append(df)\nmega_csv = pd.concat(dataframes)\nmega_csv.to_csv( \"mega.csv\", index=False, encoding='utf-8-sig')\nmega_csv.head()\n#mega_csv.shape","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"                                              tweets\n0  While we celebrate what a #COVID19vaccine mean...\n1  In honor of #MLKDay, Jadah learned about Alma ...\n2  The best pick-me-up during a hospital stay? Qu...\n3  Installation of a new hot water heater trigger...\n4  We love our nurses, and we know many of you do...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>While we celebrate what a #COVID19vaccine mean...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>In honor of #MLKDay, Jadah learned about Alma ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The best pick-me-up during a hospital stay? Qu...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Installation of a new hot water heater trigger...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>We love our nurses, and we know many of you do...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove the hashtags, mentions and unwanted characters from the tweet texts\ndef clean_text(df, text_field):\n    df[text_field] = df[text_field].str.lower()\n    print(df[text_field])\n    df[text_field] = df[text_field].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", str(elem)))  \n    return df\n\nclean_tweets = clean_text(mega_csv, 'tweets')\nclean_tweets.head()","execution_count":23,"outputs":[{"output_type":"stream","text":"0        while we celebrate what a #covid19vaccine mean...\n1        in honor of #mlkday, jadah learned about alma ...\n2        the best pick-me-up during a hospital stay? qu...\n3        installation of a new hot water heater trigger...\n4        we love our nurses, and we know many of you do...\n                               ...                        \n24995    on being in charge at a big club, lampard expl...\n24996    lampard says when you play a derby match, form...\n24997    on timo werner being on a run of not scoring, ...\n24998    frank lampard reports ben chilwell and reece j...\n24999    from 1.30pm (uk), frank lampard will look ahea...\nName: tweets, Length: 84898, dtype: object\n","name":"stdout"},{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"                                              tweets\n0  while we celebrate what a covid19vaccine means...\n1  in honor of mlkday jadah learned about alma th...\n2  the best pickmeup during a hospital stay quali...\n3  installation of a new hot water heater trigger...\n4  we love our nurses and we know many of you do ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>while we celebrate what a covid19vaccine means...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>in honor of mlkday jadah learned about alma th...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>the best pickmeup during a hospital stay quali...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>installation of a new hot water heater trigger...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>we love our nurses and we know many of you do ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove stopwords, punctuations, lemmatize and tokenize word\n# nlp = spacy.load(\"en_core_web_sm\")   #working with english only, no support for swahili\nnlp = en_core_web_sm.load()\ntokenizer = RegexpTokenizer(r'\\w+')\nlemmatizer = WordNetLemmatizer()\nstop = set(stopwords.words('english'))\npunctuation = list(string.punctuation) #already taken care of with the cleaning function.\nstop.update(punctuation)\nw_tokenizer = WhitespaceTokenizer()\n\n            \ndef furnished(text):\n    final_text = []\n    for i in w_tokenizer.tokenize(text):\n#     for i in text.split():\n        if i.lower() not in stop:\n            word = lemmatizer.lemmatize(i)\n            final_text.append(word.lower())\n    return \" \".join(final_text)\n\n\n            \nclean_tweets.tweets = clean_tweets.tweets.apply(furnished)","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_tweets.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}